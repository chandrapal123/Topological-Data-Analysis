{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ripser import ripser\n",
    "from persim import plot_diagrams\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import cv2                  \n",
    "import numpy as np  \n",
    "from tqdm import tqdm\n",
    "import os                   \n",
    "from random import shuffle  \n",
    "from zipfile import ZipFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#preprocess.\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#dl libraraies\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# specifically for cnn\n",
    "from keras.layers import Dropout, Flatten,Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Dropout \n",
    "import tensorflow as tf\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(img,cancer_type):\n",
    "    return cancer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data(cancer_type,DIR):\n",
    "    for img in os.listdir(DIR):\n",
    "        label=assign_label(img,cancer_type)\n",
    "        path = os.path.join(DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "            \n",
    "        X.append(np.array(img))\n",
    "        Z.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Z=[]\n",
    "IMG_SIZE=50\n",
    "bc_malignant_DIR='/Users/user/Desktop/breast_cancer/malignant'\n",
    "bc_benign_DIR='/Users/user/Desktop/breast_cancer/benign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benign', 'malignant']\n",
      "16\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('/Users/user/Desktop/breast_cancer'))\n",
    "make_train_data('benign',bc_benign_DIR)\n",
    "print(len(X))\n",
    "make_train_data('malignant',bc_malignant_DIR)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(Z)\n",
    "s=set(Z)\n",
    "l=[]\n",
    "for i in s:\n",
    "    l.append(i)\n",
    "cheak1=le.fit_transform(l)\n",
    "cheak2=to_categorical(cheak1,2)\n",
    "Y=to_categorical(Y,2)\n",
    "X=np.array(X)\n",
    "X=X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=[]\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "DIR1='/Users/user/Desktop/breast_cancer/benign'\n",
    "DIR2='/Users/user/Desktop/breast_cancer/malignant'\n",
    "for img in os.listdir(DIR1):\n",
    "        path = os.path.join(DIR1,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        img = color.rgb2gray(img)\n",
    "        ret, b_img = cv2.threshold(img,.5,1,cv2.THRESH_BINARY)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        X1.append(b_img)\n",
    "for img in os.listdir(DIR2):\n",
    "        path = os.path.join(DIR2,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        img = color.rgb2gray(img)\n",
    "        ret, b_img = cv2.threshold(img,.5,1,cv2.THRESH_BINARY)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        X1.append(b_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "X1=np.array(X1)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3=[]\n",
    "for i in range(31):\n",
    "    X2=[]\n",
    "    for j in range(50):\n",
    "        for k in range(50):\n",
    "            X2.append(X1[i][j][k])\n",
    "            \n",
    "    X3.append(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4=X3[:22]\n",
    "X5=X3[-10:] \n",
    "Y1=Y[:22]\n",
    "Y2=Y[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 2500)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X3=np.array(X3)\n",
    "print(X3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to return the betti numbers for dimensions 0 and 1, of the simplicial complex\n",
    "# created form a Rips filtration of a point cloud.\n",
    "def betti_nums(data, sType, scanStart, scanStop, eps = 100, showPlot = False, doSlice = False):\n",
    "    '''Inputs: -data: Your data set. Should be a list of 1's and 0's.\n",
    "    \n",
    "               -Stype: Scanning type. Should be a string either, 'ud'(up-and-down),\n",
    "                       'lr'(left-to-right), or 'rl'(right-to-left). \n",
    "                       *For down-and-up scanning, fix scanStop at the last index of \n",
    "                        your list, and alter scanStart.*\n",
    "                       **For slices, choose 'ud' for horizontal slices. Then choose scanStart \n",
    "                         and scanStop to match where you want to start and end your slice.**\n",
    "                       ***For middle-out scanning, repeat the slicing procedure, but\n",
    "                          increase scanStart and scanStop at the same time to gradually\n",
    "                          increment the size of the slice.***\n",
    "                       \n",
    "               -scanStart: Where to start scanning. For 'ud' and 'lr' scanning\n",
    "                           fix this to be the first index.\n",
    "                \n",
    "               -scanStop: Where to stop scanning. For 'du' scanning\n",
    "                          fix this to be the last index.\n",
    "                          \n",
    "               -eps: The max distance in a Rips filtration. This becomes our, \"infinity.\"\n",
    "                     This is initialized to 100. For more precision, decrease this to fit\n",
    "                     your data set.\n",
    "                     \n",
    "               -showPlot: Whether or not to show the PH diagrams. Initialized to False, change\n",
    "                          to True to show PH diagrams.\n",
    "                \n",
    "               -doSlice: Whether or not to so slice scanning. Initialized to False. Set to\n",
    "                         True if you wish to do slice scanning.\n",
    "        \n",
    "       Outputs: -(b0, b1): A tuple containing betti0 and betti1 for the scanning data set,\n",
    "                           depending on the scanning type and how much was scanned.\n",
    "    '''\n",
    "    \n",
    "    letter = np.array([[0,0]])    # Initializes an array of (1x2)-arrays.\n",
    "    \n",
    "    # Up-and-Down scanning.\n",
    "    if sType.lower() == 'ud':\n",
    "        \n",
    "        # Loops through the line with the letter data and if the kth position\n",
    "        # of the array is a 1, then the coordinates of that 1 is added as a\n",
    "        # 1x2 array to the letter array.\n",
    "        for k in range(scanStart,scanStop):\n",
    "            if data[k] == 1:\n",
    "                col = 28-int((k-1)/28)\n",
    "                row = (k-1)%28\n",
    "                letter = np.append(letter,[[row, col]], axis = 0)\n",
    "        \n",
    "        # Removes the first entry of letter, as it was a placeholder.\n",
    "        letter = np.delete(letter, 0, 0)\n",
    "        \n",
    "        # Test for the space (or just nothing), otherwise, the function breaks.\n",
    "        if len(letter) == 0:\n",
    "            return (0,0)\n",
    "        \n",
    "        # Filters the point cloud, using a Rips filtration up to a max dimension of 2.\n",
    "        diagrams = ripser(letter, maxdim = 1, metric = 'euclidean',thresh = eps)['dgms']\n",
    "        \n",
    "        # If the you want to see the shape of the data and the persistence diagram\n",
    "        # both are displayed.\n",
    "        if showPlot == True:\n",
    "            # Setting the x and y coordinates to be plotted to show the shape\n",
    "            # of the data.\n",
    "            x_data = [letter[i][0] for i in range(0,len(letter))]\n",
    "            y_data = [letter[i][1] for i in range(0,len(letter))]\n",
    "        \n",
    "            # Plots the shape of the data\n",
    "            plt.figure(1)\n",
    "            plt.plot(x_data, y_data, 'ro', scalex = True, scaley = True)\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([-1,29])\n",
    "            axes.set_ylim([-1,29])\n",
    "        \n",
    "            # Plots the PH diagram of the complex created from the Rips filtration\n",
    "            plt.figure(2)\n",
    "            plot_diagrams(diagrams, show=True, xy_range = [-0.25,5,-0.25,5])\n",
    "            \n",
    "    # Left-to-Right Scanning:\n",
    "    if sType.lower() == 'lr':\n",
    "        \n",
    "        # Tests if the the function is going to do left-to-right\n",
    "        # slice scanning or not. The scanning interval is changed\n",
    "        # accordingly.\n",
    "        if doSlice == False:\n",
    "            scanStart2 = 1\n",
    "            scanStop2 = 784\n",
    "        else:\n",
    "            scanStart2 = scanStart\n",
    "            scanStop2 = 784\n",
    "        \n",
    "        # Loops through the line with the letter data and if the kth position\n",
    "        # of the array is a 1, then the coordinates of that 1 is added as a\n",
    "        # 1x2 array to the letter array.\n",
    "        for k in range(scanStart2,scanStop2):\n",
    "            if data[k] == 1:\n",
    "                row = 28-int((k-1)/28)\n",
    "                col = (k-1)%28\n",
    "                letter = np.append(letter,[[row, col]], axis = 0)\n",
    "        \n",
    "        # Removes the first entry of letter, as it was a placeholder.\n",
    "        letter = np.delete(letter, 0, 0)\n",
    "        \n",
    "        # Test for the space (or just nothing), otherwise, the function breaks.\n",
    "        if len(letter) == 0:\n",
    "            return (0,0)\n",
    "        \n",
    "        # Rearranges the xy-coordinates to do left-to-right scanning.\n",
    "        y_data = np.array([letter[i][0] for i in range(0,len(letter)) for j in range(1,int(scanStop/28)) if letter[i][1] == j])\n",
    "        x_data = np.array([letter[i][1] for i in range(0,len(letter)) for j in range(1,int(scanStop/28)) if letter[i][1] == j])\n",
    "        \n",
    "        # Creates a new array with the the xy-coordinates oriented properly\n",
    "        # for left-to-right scanning.\n",
    "        letter2 = np.array([x_data,y_data])\n",
    "        letter2 = np.transpose(letter2)\n",
    "        \n",
    "        # Tests again to make sure there is something in the letter2 array.\n",
    "        # If there isn't, b0 = b1 = 0.\n",
    "        if len(letter2) == 0:\n",
    "            return (0,0)\n",
    "        \n",
    "        # Filters the point cloud, using a Rips filtration up to a max dimension of 2.\n",
    "        diagrams = ripser(letter2, maxdim = 1, metric = 'euclidean',thresh = eps)['dgms']\n",
    "        \n",
    "        # If the you want to see the shape of the data and the persistence diagram\n",
    "        # both are displayed.\n",
    "        if showPlot == True:\n",
    "            # Plots the shape of the data\n",
    "            plt.figure(1)\n",
    "            plt.plot(x_data, y_data, 'ro', scalex = True, scaley = True)\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([-1,29])\n",
    "            axes.set_ylim([-1,29])\n",
    "        \n",
    "            # Plots the PH diagram of the complex created from the Rips filtration\n",
    "            plt.figure(2)\n",
    "            plot_diagrams(diagrams, show=True, xy_range = [-0.25,5,-0.25,5])\n",
    "    \n",
    "    \n",
    "    # Right-to-Left Scanning:\n",
    "    if sType.lower() == 'rl':\n",
    "        \n",
    "        # Loops through the line with the letter data and if the kth position\n",
    "        # of the array is a 1, then the coordinates of that 1 is added as a\n",
    "        # 1x2 array to the letter array.\n",
    "        for k in range(1,785):\n",
    "            if data[k] == 1:\n",
    "                row = 28-int((k-1)/28)\n",
    "                col = 28-(k-1)%28\n",
    "                letter = np.append(letter,[[row, col]], axis = 0)\n",
    "    \n",
    "        # Removes the first entry of letter, as it was a placeholder.\n",
    "        letter = np.delete(letter, 0, 0)\n",
    "        \n",
    "        # Test for the space (or just nothing), otherwise, the function breaks.\n",
    "        if len(letter) == 0:\n",
    "            return (0,0)\n",
    "        \n",
    "        # Rearranges the xy-coordinates to do right-to-left scanning.\n",
    "        y_data = np.array([letter[i][0] for i in range(0,len(letter)) for j in range(1,int(scanStop/10)) if letter[i][1] == j])\n",
    "        x_data = np.array([letter[i][1] for i in range(0,len(letter)) for j in range(1,int(scanStop/10)) if letter[i][1] == j])\n",
    "        \n",
    "        # Creates a new array with the the xy-coordinates oriented properly\n",
    "        # for Right-to-Left scanning.\n",
    "        letter2 = np.array([x_data,y_data])\n",
    "        letter2 = np.transpose(letter2)\n",
    "        \n",
    "        # Tests again to make sure there is something in the letter2 array.\n",
    "        # If there isn't, b0 = b1 = 0.\n",
    "        if len(letter2) == 0:\n",
    "            return (0,0)\n",
    "        \n",
    "        # Filters the point cloud, using a Rips filtration up to a max dimension of 2.\n",
    "        diagrams = ripser(letter2, maxdim = 1, metric = 'euclidean',thresh = eps)['dgms']\n",
    "        \n",
    "        # If the you want to see the shape of the data and the persistence diagram\n",
    "        # both are displayed.\n",
    "        if showPlot == True:\n",
    "            # Plots the shape of the data\n",
    "            plt.figure(1)\n",
    "            plt.plot(x_data, y_data, 'ro', scalex = True, scaley = True)\n",
    "            axes = plt.gca()\n",
    "            axes.set_xlim([-1,29])\n",
    "            axes.set_ylim([-1,29])\n",
    "        \n",
    "            # Plots the PH diagram of the complex created from the Rips filtration\n",
    "            plt.figure(2)\n",
    "            plot_diagrams(diagrams, show=True, xy_range = [-0.25,5,-0.25,5])\n",
    "        \n",
    "    # Calculates the 0-dim betti number.\n",
    "    betti0 = [1 for x in diagrams[0] if float('inf') in x]\n",
    "            \n",
    "    # If there is a 1-dim betti number, it is returned.\n",
    "    if len(diagrams) == 2:\n",
    "        \n",
    "        # Calculates the 1-dim betti number.\n",
    "        betti1 = [1 for x in diagrams[1] if float('inf') in x]\n",
    "        \n",
    "        # Returns the betti numbers.\n",
    "        return (len(betti0),len(betti1))\n",
    "    \n",
    "    # Otherwise b1 = 0.\n",
    "    else:\n",
    "        # Returns the betti numbers.\n",
    "        return(len(betti0),0)\n",
    "\n",
    "    \n",
    "# Function to create classification vectors for data sets.\n",
    "def classificationVector(dataSet, flag):\n",
    "    '''Inputs: -dataSet: The data set to be analyzed.\n",
    "               -flag: Flag to control single vector analysis or whole data set analysis.\n",
    "                       Either 'single' or 'whole'.\n",
    "    \n",
    "       Outputs: -dataVect: A matrix containing vectors of weights corresponding\n",
    "                           to signatures from the data set. (Called dataVect for\n",
    "                           a single vector, or totalDataVect for the whole set.)\n",
    "    '''\n",
    "    \n",
    "    # List with the scanning types to iterate through.\n",
    "    scanTypes = ['ud', 'du', 'lr', 'mo-hori', 'dist1', 'ptdim', 'shortlr','ends', 'width']\n",
    "    \n",
    "    # Creates classification vectors for each character in the data set.\n",
    "    if flag.lower() == 'whole':\n",
    "        \n",
    "        # List holding numpy arrays of each classification vector.\n",
    "        totalDataVect = []\n",
    "    \n",
    "        j = 0    # loop control variable.\n",
    "    \n",
    "        # Iterates through the data set and creates classification vectors\n",
    "        # for each character.\n",
    "        while j != len(dataSet):\n",
    "            \n",
    "            letter_one_line = dataSet[j,:]    # Loads the data for one character from the data set.\n",
    "            dataVect = np.array([])           # Creates an empty array to hold the classification features\n",
    "        \n",
    "            # Finds the total betti numbers for each data set and places it in the positions 0 and 1\n",
    "            # of the vector.\n",
    "            (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 784, eps = 1.42, showPlot = False, doSlice = False)\n",
    "            dataVect = np.append(dataVect,b0)\n",
    "            dataVect = np.append(dataVect,b1)\n",
    "        \n",
    "            # Iterating through the different scan types and adding to dataVect\n",
    "            # features depending on the scan type. Each feature is a number between\n",
    "            # 0 and 1. For betti numbers this is calculated as (100-bn)/100, where\n",
    "            # n = 0 or 1. For width this is calulated as width/100.\n",
    "            for sc in scanTypes:\n",
    "                \n",
    "                # bottom-to-top scanning is done on the bottom half of the character.\n",
    "                if sc.lower() == 'du':\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'ud', 353, 784, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                    dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "        \n",
    "                # Horizontal middle-out scanning on the middle third of the character.\n",
    "                elif sc.lower() == 'mo-hori':\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'ud', 196, 596, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                    dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "        \n",
    "                # Width scanning. The scan interval is kept at a fixed [50-i, 50+i] and i is increased until\n",
    "                # either b1 is greater than or equal to 1, or the entire character is scanned.\n",
    "                # This width gives the 'time' when the first 1D 'hole' is found. This is calculated as\n",
    "                # the length of the interval which is 50+i - (50-i) = 2*i. It is then reweighted with division\n",
    "                # by 100.\n",
    "                elif sc.lower() == 'width':\n",
    "                    \n",
    "                    scanWidth = 0    # Initializes scanWidth to be zero.\n",
    "                    \n",
    "                    # Increases the width in increments of 10, with i ranging from 1 to 50.\n",
    "                    for i in range(1,392,28):\n",
    "                        \n",
    "                        # The beginning and end of the scan interval.\n",
    "                        scStart = 392-i\n",
    "                        scStop = 392+i\n",
    "                        \n",
    "                        # Calculates the betti numbers for the character at the current width.\n",
    "                        (b0,b1) = betti_nums(letter_one_line, 'lr', scStart, scStop, eps = 1.42, showPlot = False, doSlice = False)\n",
    "\n",
    "                        # If b1 is greater than or equal to 1, the width calculated as 2*i, and the loop is broken.\n",
    "                        if b1 >= 1:\n",
    "                            scanWidth = 2*i\n",
    "                            break\n",
    "                    \n",
    "                    # Appends the width to the classification vector.\n",
    "                    dataVect = np.append(dataVect,scanWidth/2500)\n",
    "                    \n",
    "                    scanWidth = 0    # Resets scanWidth back to zero.\n",
    "        \n",
    "                # Up-and-Down scanning, but with the 'infinity' being equal to 1. This connects the skeleton\n",
    "                # of the character, but without filling in the 'holes' that get filled in a distance of ~1.42.\n",
    "                elif sc.lower() == 'dist1':\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 784, eps = 1.0, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                    dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "        \n",
    "                # Calculates the number of 'pixels' in the character. This is equivalent to the number of points\n",
    "                # in the point cloud (i.e. the number of 1's in the data for the character).\n",
    "                elif sc.lower() == 'ptdim':\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 784, eps = 0, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                    dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "            \n",
    "                # Left-to-Right scanning in a shorter interval than normal. This is done to pick up any 'endpoints'\n",
    "                # of characters that are missed in the normal left-to-right scan.\n",
    "                elif sc.lower() == 'shortlr':\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'lr', 1, 364, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                    dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "                    \n",
    "                # Short scanning Up-and-Down, Down-and-Up, and Left-to-Right. Effectively calculating the ends\n",
    "                # of the structure if the middle is excised.\n",
    "                elif sc.lower() == 'ends':\n",
    "                    (b0u,b1u) = betti_nums(letter_one_line,'ud', 1,168, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    (b0d,b1d) = betti_nums(letter_one_line,'ud', 616,784, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    (b0l,b1l) = betti_nums(letter_one_line,'lr', 1,225, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect, (2500-(b0u+b0d+b0l))/2500)\n",
    "            \n",
    "                \n",
    "                # The remaining scan types (ud and lr) on half of the character.\n",
    "                else:\n",
    "                    (b0,b1) = betti_nums(letter_one_line, sc, 1, 674, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                    dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                    dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "        \n",
    "            # Adds the classifcation vector for the jth character to the total list of vectors.\n",
    "            totalDataVect.append(dataVect)\n",
    "            \n",
    "            # Increments j.\n",
    "            j += 1\n",
    "        \n",
    "        # Returns the total list of classification vectors.\n",
    "        return totalDataVect\n",
    "    \n",
    "    # Creates a classification vector for one character.\n",
    "    elif flag.lower() == 'single':\n",
    "        \n",
    "        letter_one_line = dataSet    # Loads the data for the one character.\n",
    "        dataVect = np.array([])      # Creates an empty array to hold the classification features\n",
    "        \n",
    "        # Finds the total betti numbers for each data set and places it in the positions 0 and 1\n",
    "        # of the vector.\n",
    "        (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 2500, eps = 1.42, showPlot = False, doSlice = False)\n",
    "        dataVect = np.append(dataVect,b0)\n",
    "        dataVect = np.append(dataVect,b1)\n",
    "        \n",
    "        # Iterating through the different scan types and adding to dataVect\n",
    "        # features depending on the scan type. Each feature is a number between\n",
    "        # 0 and 1. For betti numbers this is calculated as (100-bn)/100, where\n",
    "        # n = 0 or 1. For width this is calulated as width/100.\n",
    "        for sc in scanTypes:\n",
    "            \n",
    "            # bottom-to-top scanning is done on the bottom half of the character.\n",
    "            if sc.lower() == 'du':\n",
    "                (b0,b1) = betti_nums(letter_one_line, 'ud', 390, 784, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "            \n",
    "            # Horizontal middle-out scanning on the middle third of the character.\n",
    "            elif sc.lower() == 'mo-hori':\n",
    "                (b0,b1) = betti_nums(letter_one_line, 'ud', 196, 596, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "            \n",
    "            # Width scanning. The scan interval is kept at a fixed [50-i, 50+i] and i is increased until\n",
    "            # either b1 is greater than or equal to 1, or the entire character is scanned.\n",
    "            # This width gives the 'time' when the first 1D 'hole' is found. This is calculated as\n",
    "            # the width of the interval which is 50+i - (50-i) = 2*i. It is then reweighted with division\n",
    "            # by 100.\n",
    "            elif sc.lower() == 'width':\n",
    "                \n",
    "                scanWidth = 0    # Initializes scanWidth to be zero.\n",
    "                \n",
    "                # Increases the width in increments of 10, with i ranging from 1 to 50.\n",
    "                for i in range(1,392,28):\n",
    "                    \n",
    "                    # The beginning and end of the scan interval.\n",
    "                    scStart = 392-i\n",
    "                    scStop = 392+i\n",
    "                    \n",
    "                    # Calculates the betti numbers for the character at the current width.\n",
    "                    (b0,b1) = betti_nums(letter_one_line, 'lr', scStart, scStop, eps = 1.42, showPlot = False, doSlice = False)\n",
    "\n",
    "                    # If b1 is greater than or equal to 1, the width calculated as 2*i, and the loop is broken.\n",
    "                    if b1 >= 1:\n",
    "                        scanWidth = 2*i\n",
    "                        break\n",
    "                \n",
    "                # Appends the width to the classification vector.\n",
    "                dataVect = np.append(dataVect,scanWidth/2500)\n",
    "                \n",
    "                scanWidth = 0    # Resets scanWidth back to zero.\n",
    "        \n",
    "            # Up-and-Down scanning, but with the 'infinity' being equal to 1. This connects the skeleton\n",
    "            # of the character, but without filling in the 'holes' that get filled in a distance of ~1.42.\n",
    "            elif sc.lower() == 'dist1':\n",
    "                (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 784, eps = 1.0, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "        \n",
    "            # Calculates the number of 'pixels' in the character. This is equivalent to the number of points\n",
    "            # in the point cloud (i.e. the number of 1's in the data for the character).\n",
    "            elif sc.lower() == 'ptdim':\n",
    "                (b0,b1) = betti_nums(letter_one_line, 'ud', 1, 784, eps = 0, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "            \n",
    "            # Left-to-Right scanning in a shorter interval than normal. This is done to pick up any 'endpoints'\n",
    "            # of characters that are missed in the normal left-to-right scan.\n",
    "            elif sc.lower() == 'shortlr':\n",
    "                (b0,b1) = betti_nums(letter_one_line, 'lr', 1, 313, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "            \n",
    "            # Short scanning Up-and-Down, Down-and-Up, and Left-to-Right. Effectively calculating the ends\n",
    "            # of the structure if the middle is excised.\n",
    "            elif sc.lower() == 'ends':\n",
    "                (b0u,b1u) = betti_nums(letter_one_line,'ud', 1,165, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                (b0d,b1d) = betti_nums(letter_one_line,'ud', 627,784, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                (b0l,b1l) = betti_nums(letter_one_line,'lr', 1,235, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect, (2500-(b0u+b0d+b0l))/2500)\n",
    "            \n",
    "            # The remaining scan types (ud and lr) on half of the character.\n",
    "            else:\n",
    "                (b0,b1) = betti_nums(letter_one_line, sc, 1, 674, eps = 1.42, showPlot = False, doSlice = False)\n",
    "                dataVect = np.append(dataVect,(2500-b0)/2500)\n",
    "                dataVect = np.append(dataVect,(2500-b1)/2500)\n",
    "        \n",
    "        return dataVect    # Returns the single classification vector.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X4,Y1,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-940942f8398c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassificationVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'whole'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_te\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassificationVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'whole'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-79-556a9d38d777>\u001b[0m in \u001b[0;36mclassificationVector\u001b[1;34m(dataSet, flag)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[0mletter_one_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m# Loads the data for one character from the data set.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m             \u001b[0mdataVect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m           \u001b[1;31m# Creates an empty array to hold the classification features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "x_tr = classificationVector(x_train,'whole')\n",
    "x_te=classificationVector(x_test,'whole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense # Dense layers are \"fully connected\" layers\n",
    "from keras.models import Sequential # Documentation: https://keras.io/models/sequential/\n",
    "from keras.layers import Dropout, Flatten,Activation\n",
    "image_size =18 \n",
    "num_classes = 2 \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# The input layer requires the special input_shape parameter which should match\n",
    "# the shape of our training data.\n",
    "model.add(Dense(units=32, activation='sigmoid', input_shape=(image_size,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)\n",
    "model.summary()\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit(x_tr, y_train, batch_size=128, epochs=100,validation_data = (x_te,y_test),\n",
    "                              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
